{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 840806,
          "sourceType": "datasetVersion",
          "datasetId": 59760
        }
      ],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "alessiocorrado99_animals10_path = kagglehub.dataset_download('alessiocorrado99/animals10')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "7TC-zYMFntAG"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas necessárias\n",
        "import kagglehub as kh\n",
        "\n",
        "# Import libraries\n",
        "import os  # For interacting with the file system\n",
        "import shutil  # For managing files and directories in a cross-platform manner\n",
        "import keras  # For building deep learning models\n",
        "import numpy as np  # For numerical operations on arrays\n",
        "import pandas as pd # For data manipulation\n",
        "from glob import glob  # For finding file paths\n",
        "from tqdm import tqdm  # For progress bars\n",
        "\n",
        "# Data visualization\n",
        "import seaborn as sns  # For statistical visualizations\n",
        "import plotly.graph_objs as go  # For interactive visualizations\n",
        "import matplotlib.pyplot as plt  # For creating static plots\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "# Model architecture\n",
        "from keras import Sequential  # For building sequential models\n",
        "from keras.models import load_model  # For loading pre-trained models\n",
        "from keras.layers import Dense, GlobalAvgPool2D as GAP, Dropout  # For defining model layers\n",
        "\n",
        "# Training callbacks\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Pre-trained models\n",
        "from tensorflow.keras.applications import InceptionV3, ResNet152V2, Xception\n",
        "\n",
        "# Models\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Model visualization\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Data preprocessing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "\n",
        "# Image preprocessing for K-Means Model\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from skimage import color\n",
        "from skimage import io\n",
        "from skimage import img_as_ubyte\n",
        "from skimage.transform import resize\n",
        "from scipy.stats import mode\n",
        "from skimage.feature import hog\n",
        "from sklearn.decomposition import PCA\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T16:27:09.029798Z",
          "iopub.execute_input": "2024-11-24T16:27:09.03067Z",
          "iopub.status.idle": "2024-11-24T16:27:09.041197Z",
          "shell.execute_reply.started": "2024-11-24T16:27:09.030592Z",
          "shell.execute_reply": "2024-11-24T16:27:09.039784Z"
        },
        "id": "-mgSFYXjntAH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download latest version\n",
        "path = kh.dataset_download(\"alessiocorrado99/animals10\")\n",
        "\n",
        "print(\"Caminho para os arquivos:\", path)\n",
        "\n",
        "# Get a list of class names from the data path\n",
        "data_path = f\"{path}/raw-img\"\n",
        "\n",
        "class_names = sorted(os.listdir(data_path))\n",
        "\n",
        "# Count the number of classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Print the class names and the total number of classes\n",
        "print(\"Nomes das classes: \\n\", class_names)\n",
        "print(\"Número de classes:\", num_classes)\n",
        "\n",
        "# Get the number of samples in each class\n",
        "class_sizes = []\n",
        "for name in class_names:\n",
        "    class_size = len(os.listdir(data_path + \"/\" + name))\n",
        "    class_sizes.append(class_size)\n",
        "\n",
        "# Print the class distribution\n",
        "print(\"Distribuição das classes:\\n\", class_sizes)\n",
        "\n",
        "# to convert lists to dictionary\n",
        "class_name_size = dict(zip(class_names, class_sizes))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T16:27:15.514795Z",
          "iopub.execute_input": "2024-11-24T16:27:15.515202Z",
          "iopub.status.idle": "2024-11-24T16:27:17.50233Z",
          "shell.execute_reply.started": "2024-11-24T16:27:15.515169Z",
          "shell.execute_reply": "2024-11-24T16:27:17.500986Z"
        },
        "id": "SxuXhu1sntAI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data\n",
        "data = go.Pie(labels=class_names, values=class_sizes)\n",
        "\n",
        "# Define the layout\n",
        "layout = go.Layout(title={\"text\": \"Class Distribution\", \"x\": 0.5})\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "# Display the figure\n",
        "fig.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T16:28:01.817561Z",
          "iopub.execute_input": "2024-11-24T16:28:01.818087Z",
          "iopub.status.idle": "2024-11-24T16:28:02.266404Z",
          "shell.execute_reply.started": "2024-11-24T16:28:01.818048Z",
          "shell.execute_reply": "2024-11-24T16:28:02.265061Z"
        },
        "id": "AUTEFlKCntAJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a bar graph of the number of images in each class\n",
        "\n",
        "# Set the size of the figure\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "# Plot a bar chart using the class names as the x-axis and class sizes as the y-axis\n",
        "sns.barplot(x=class_names, y=class_sizes)\n",
        "\n",
        "# Add a grid to the plot\n",
        "plt.grid()\n",
        "\n",
        "# Add a horizontal line to show the mean number of images across all classes\n",
        "plt.axhline(np.mean(class_sizes), color='black', linestyle=':', label=\"Average number of images per class\")\n",
        "\n",
        "# Add a legend to the plot\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T16:28:07.692431Z",
          "iopub.execute_input": "2024-11-24T16:28:07.692943Z",
          "iopub.status.idle": "2024-11-24T16:28:08.098242Z",
          "shell.execute_reply.started": "2024-11-24T16:28:07.692895Z",
          "shell.execute_reply": "2024-11-24T16:28:08.096775Z"
        },
        "id": "MlefeuLxntAK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the directory where the sampled data will be saved\n",
        "sampled_data_path = './sampled-data'\n",
        "\n",
        "# Create the sampled data directory if it doesn't exist\n",
        "if not os.path.exists(sampled_data_path):\n",
        "    os.mkdir(sampled_data_path)\n",
        "\n",
        "# Set the percentage of each class to sample\n",
        "sample_percent = 0.1\n",
        "\n",
        "# Define a dictionary that maps the original class names to their English names\n",
        "class_names_dict = {\n",
        "    'cane': 'dog',\n",
        "    'cavallo': 'horse',\n",
        "    'elefante': 'elephant',\n",
        "    'farfalla': 'butterfly',\n",
        "    'gallina': 'chicken',\n",
        "    'gatto': 'cat',\n",
        "    'mucca': 'cow',\n",
        "    'pecora': 'sheep',\n",
        "    'ragno': 'spider',\n",
        "    'scoiattolo': 'squirrel'\n",
        "}\n",
        "\n",
        "# Loop through each class directory and copy 2000 images or less to the sampled data directory\n",
        "for class_name in os.listdir(data_path):\n",
        "    # Get the path to the original class directory\n",
        "    class_path = os.path.join(data_path, class_name)\n",
        "    # Get the English name of the class\n",
        "    class_name_en = class_names_dict[class_name]\n",
        "    # Get the path to the sampled class directory\n",
        "    sampled_class_path = os.path.join(sampled_data_path, class_name_en)\n",
        "    # Create the sampled class directory and fill it up only if it doesn't exist\n",
        "    if not os.path.exists(sampled_class_path):\n",
        "        os.mkdir(sampled_class_path)\n",
        "        # Get a list of all the image files in the class directory\n",
        "        image_files = os.listdir(class_path)\n",
        "        # Calculate the number of images to sample\n",
        "        image_class_size = class_name_size[class_name]\n",
        "        if image_class_size > 2000:\n",
        "            num_images = 2000\n",
        "        else:\n",
        "            num_images = int(image_class_size)\n",
        "        # Sample the images\n",
        "        sampled_images = np.random.choice(image_files, size=num_images, replace=False)\n",
        "        # Copy the sampled images to the sampled class directory\n",
        "        for image_name in sampled_images:\n",
        "            src_path = os.path.join(class_path, image_name)\n",
        "            dst_path = os.path.join(sampled_class_path, image_name)\n",
        "            shutil.copyfile(src_path, dst_path)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T16:28:19.545664Z",
          "iopub.execute_input": "2024-11-24T16:28:19.546984Z",
          "iopub.status.idle": "2024-11-24T16:30:01.679333Z",
          "shell.execute_reply.started": "2024-11-24T16:28:19.546928Z",
          "shell.execute_reply": "2024-11-24T16:30:01.678038Z"
        },
        "id": "xoxODkoontAM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of class names from the sampled data directory\n",
        "class_names = sorted(os.listdir(sampled_data_path))\n",
        "\n",
        "# Get the number of samples in each class\n",
        "class_sizes = []\n",
        "for name in class_names:\n",
        "    # Get the number of samples in the class directory\n",
        "    class_size = len(os.listdir(os.path.join(sampled_data_path, name)))\n",
        "    class_sizes.append(class_size)\n",
        "\n",
        "# Print the class distribution\n",
        "print(\"Class Distribution:\\n\", class_sizes)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T16:32:49.220678Z",
          "iopub.execute_input": "2024-11-24T16:32:49.221945Z",
          "iopub.status.idle": "2024-11-24T16:32:49.242893Z",
          "shell.execute_reply.started": "2024-11-24T16:32:49.221899Z",
          "shell.execute_reply": "2024-11-24T16:32:49.24147Z"
        },
        "id": "bDVE0zWCntAN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data\n",
        "data = go.Pie(labels=class_names, values=class_sizes)\n",
        "\n",
        "# Define the layout\n",
        "layout = go.Layout(title={\"text\": \"Class Distribution\", \"x\": 0.5})\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "\n",
        "# Display the figure\n",
        "fig.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T16:32:53.823125Z",
          "iopub.execute_input": "2024-11-24T16:32:53.823549Z",
          "iopub.status.idle": "2024-11-24T16:32:53.836458Z",
          "shell.execute_reply.started": "2024-11-24T16:32:53.823513Z",
          "shell.execute_reply": "2024-11-24T16:32:53.835041Z"
        },
        "id": "rwV-vQTantAN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Generator with the specified image transformations and preprocessing\n",
        "# rescale: normalizes pixel values from 0-255 to 0-1\n",
        "# horizontal_flip: randomly flips images horizontally\n",
        "# vertical_flip: randomly flips images vertically\n",
        "# rotation_range: randomly rotates images by a given range in degrees\n",
        "# validation_split: splits the data into training and validation sets, with 20% of the data used for validation\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    rotation_range=20,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data from the specified directory and apply the generator\n",
        "# target_size: resizes the images to a specified size\n",
        "# class_mode: specifies the type of label encoding, binary for 2 classes\n",
        "# batch_size: specifies the number of samples per batch\n",
        "# shuffle: shuffles the data after each epoch\n",
        "# subset: specifies the subset of data to load, in this case, the training set\n",
        "train_data_cnn = data_generator.flow_from_directory(\n",
        "    sampled_data_path,\n",
        "    target_size=(256,256),\n",
        "    class_mode='binary',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data from the specified directory and apply the generator\n",
        "# subset: specifies the subset of data to load, in this case, the validation set\n",
        "valid_data_cnn = data_generator.flow_from_directory(\n",
        "    sampled_data_path,\n",
        "    target_size=(256,256),\n",
        "    class_mode='binary',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Dados de treino\n",
        "train_data_ann = data_generator.flow_from_directory(\n",
        "    sampled_data_path,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    subset='training',\n",
        "    class_mode='categorical'  # Ajuste para gerar rótulos *one-hot*\n",
        ")\n",
        "\n",
        "# Dados de validação\n",
        "valid_data_ann = data_generator.flow_from_directory(\n",
        "    sampled_data_path,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical',  # Ajuste para gerar rótulos *one-hot*\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T16:33:00.961772Z",
          "iopub.execute_input": "2024-11-24T16:33:00.963095Z",
          "iopub.status.idle": "2024-11-24T16:33:03.729418Z",
          "shell.execute_reply.started": "2024-11-24T16:33:00.96304Z",
          "shell.execute_reply": "2024-11-24T16:33:03.728321Z"
        },
        "id": "K9P5tWcwntAO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image, image_title=None):\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(image)\n",
        "\n",
        "    # Set the title of the plot if provided\n",
        "    plt.title(image_title)\n",
        "\n",
        "    # Turn off the axes in the plot\n",
        "    plt.axis('off')\n",
        "\n",
        "def get_random_data(data_tuple):\n",
        "\n",
        "    images, labels = data_tuple\n",
        "    # get a random index for an image in the dataset\n",
        "    idx = np.random.randint(len(images))\n",
        "\n",
        "    # select the image and its corresponding label using the random index\n",
        "    image, label = images[idx], labels[idx]\n",
        "\n",
        "    # return the selected image and label\n",
        "    return image, label\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T16:33:11.458417Z",
          "iopub.execute_input": "2024-11-24T16:33:11.458903Z",
          "iopub.status.idle": "2024-11-24T16:33:11.466484Z",
          "shell.execute_reply.started": "2024-11-24T16:33:11.458858Z",
          "shell.execute_reply": "2024-11-24T16:33:11.465169Z"
        },
        "id": "oCEvxkAVntAP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size for the plot\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "# Initialize a counter for the subplots\n",
        "counter=1\n",
        "\n",
        "# Loop over the train dataset\n",
        "for images, labels in iter(train_data_cnn):\n",
        "\n",
        "    # Get a random image and label\n",
        "    image, label = get_random_data([images, labels])\n",
        "\n",
        "    # Plot the image with its class name as the title\n",
        "    plt.subplot(5,5,counter)\n",
        "    show_image(image, image_title=f\"Class : {class_names[int(label)]}\")\n",
        "\n",
        "    # Increment the counter\n",
        "    counter+=1\n",
        "\n",
        "    # End the loop when 25 images have been plotted\n",
        "    if counter>=26: break\n",
        "\n",
        "# Adjust the layout and display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T16:33:17.496537Z",
          "iopub.execute_input": "2024-11-24T16:33:17.49711Z",
          "iopub.status.idle": "2024-11-24T16:33:35.483812Z",
          "shell.execute_reply.started": "2024-11-24T16:33:17.497073Z",
          "shell.execute_reply": "2024-11-24T16:33:35.482446Z"
        },
        "id": "3pt7_f1UntAQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de treino/validação do modelo\n",
        "def fit_model_cnn(model, name, epochs=5):\n",
        "    # Set up the EarlyStopping and ModelCheckpoint callbacks to monitor the training process and save the best model weights.\n",
        "    cbs = [\n",
        "      EarlyStopping(patience=3, restore_best_weights=True),\n",
        "      ModelCheckpoint(name + \".keras\", save_best_only=True)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_data_cnn, validation_data=valid_data_cnn,\n",
        "        epochs=epochs, callbacks=cbs\n",
        "    )\n",
        "\n",
        "    return history\n",
        "\n",
        "def fit_model_ann(model, epochs=5):\n",
        "    cbs = [\n",
        "      EarlyStopping(patience=3, restore_best_weights=True),\n",
        "      ModelCheckpoint(\"AnnAnimalImageClassifier.keras\", save_best_only=True)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_data_ann, validation_data=valid_data_ann,\n",
        "        epochs=epochs, callbacks=cbs\n",
        "    )\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T16:35:27.462345Z",
          "iopub.execute_input": "2024-11-24T16:35:27.462827Z",
          "iopub.status.idle": "2024-11-24T16:35:27.471411Z",
          "shell.execute_reply.started": "2024-11-24T16:35:27.462791Z",
          "shell.execute_reply": "2024-11-24T16:35:27.469943Z"
        },
        "id": "Hj4KITYDntAQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Construindo um modelo ANN\n",
        "model = models.Sequential([\n",
        "    # Achatar a entrada (imagens de 256x256x3 para um vetor unidimensional)\n",
        "    layers.Flatten(input_shape=(256, 256, 3)),\n",
        "\n",
        "    # Camadas densas\n",
        "    layers.Dense(512, activation='relu'),  # Primeira camada totalmente conectada\n",
        "    layers.Dropout(0.5),  # Dropout para evitar overfitting\n",
        "\n",
        "    layers.Dense(256, activation='relu'),  # Segunda camada\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(128, activation='relu'),  # Terceira camada\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    # Camada de saída (para classificação multi-classe)\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Resumo do modelo\n",
        "model.summary()\n",
        "\n",
        "# Compilando o modelo\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),  # Perda para classificação multi-classe\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Treinando o modelo\n",
        "model_history = fit_model_ann(model)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T16:35:56.362432Z",
          "iopub.execute_input": "2024-11-24T16:35:56.36323Z",
          "iopub.status.idle": "2024-11-24T17:47:05.799721Z",
          "shell.execute_reply.started": "2024-11-24T16:35:56.363193Z",
          "shell.execute_reply": "2024-11-24T17:47:05.797793Z"
        },
        "id": "2G5yKQ63ntAQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para processar uma imagem e garantir que tenha 3 canais (RGB) e um tamanho fixo\n",
        "def process_image(image_path, target_size=(128, 128)):\n",
        "    try:\n",
        "        # Carrega a imagem\n",
        "        image = io.imread(image_path)\n",
        "\n",
        "        # Converte para RGB se necessário\n",
        "        if len(image.shape) == 2:  # Tons de cinza\n",
        "            image = color.gray2rgb(image)\n",
        "        elif image.shape[-1] == 4:  # RGBA\n",
        "            image = color.rgba2rgb(image)\n",
        "\n",
        "        # Redimensiona a imagem para o tamanho desejado\n",
        "        image = resize(image, target_size, anti_aliasing=True)\n",
        "\n",
        "        # Converte para uint8 caso necessário\n",
        "        image = img_as_ubyte(image)\n",
        "\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Caminho das imagens no diretório amostrado\n",
        "processed_images = []\n",
        "labels = []\n",
        "\n",
        "for class_name in class_names:\n",
        "    class_path = os.path.join(sampled_data_path, class_name)\n",
        "    for image_file in os.listdir(class_path):\n",
        "        image_path = os.path.join(class_path, image_file)\n",
        "\n",
        "        # Processa a imagem\n",
        "        image = process_image(image_path)\n",
        "\n",
        "        if image is not None:\n",
        "            processed_images.append(image)\n",
        "            labels.append(class_name)\n",
        "\n",
        "print(f\"Total de imagens processadas: {len(processed_images)}\")\n",
        "\n",
        "# Converter para NumPy array\n",
        "processed_images = np.array(processed_images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Normalizar os dados\n",
        "processed_images = processed_images / 255.0\n",
        "\n",
        "# Codificar rótulos com LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Divisão do dataset em conjunto de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    processed_images.reshape(len(processed_images), -1),  # Flatten as imagens\n",
        "    labels_encoded,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels_encoded\n",
        ")\n",
        "\n",
        "print(f\"Formato do conjunto de treinamento: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Formato do conjunto de teste: {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "# Usar MiniBatchKMeans para clustering\n",
        "# Definir o número de clusters igual ao número de classes\n",
        "n_clusters = len(class_names)  # Número de classes\n",
        "kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, batch_size=100)\n",
        "kmeans.fit(X_train)\n",
        "\n",
        "# Predizer os clusters para o conjunto de teste\n",
        "y_pred = kmeans.predict(X_test)\n",
        "\n",
        "# Ajustar rótulos de cluster para coincidir com as classes reais\n",
        "labels_map = {}\n",
        "for cluster_idx in range(n_clusters):\n",
        "    mask = (kmeans.labels_ == cluster_idx)\n",
        "    true_labels = y_train[mask]\n",
        "    if len(true_labels) > 0:\n",
        "        # Corrigir acesso ao atributo \"mode\"\n",
        "        labels_map[cluster_idx] = mode(true_labels, keepdims=True).mode[0]\n",
        "\n",
        "# Mapeando as predições para os rótulos corretos\n",
        "y_pred_mapped = np.array([labels_map[cluster] for cluster in y_pred])\n",
        "\n",
        "# Decodificar os rótulos de volta para os nomes das classes\n",
        "y_pred_mapped = label_encoder.inverse_transform(y_pred_mapped)\n",
        "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "# Avaliar o desempenho do modelo\n",
        "accuracy = accuracy_score(y_test_decoded, y_pred_mapped)\n",
        "print(f\"Acurácia do MiniBatchKMeans: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T17:54:36.009242Z",
          "iopub.execute_input": "2024-11-24T17:54:36.013271Z",
          "iopub.status.idle": "2024-11-24T18:06:25.571672Z",
          "shell.execute_reply.started": "2024-11-24T17:54:36.013162Z",
          "shell.execute_reply": "2024-11-24T18:06:25.570408Z"
        },
        "id": "_uBn7NvzntAR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para extrair recursos usando HOG\n",
        "def extract_features(images):\n",
        "    features = []\n",
        "    for image in images:\n",
        "        # Ajustar para o uso de channel_axis em vez de multichannel\n",
        "        feature = hog(\n",
        "            image,\n",
        "            orientations=9,\n",
        "            pixels_per_cell=(8, 8),\n",
        "            cells_per_block=(2, 2),\n",
        "            channel_axis=-1  # Especifica que os canais estão no último eixo\n",
        "        )\n",
        "        features.append(feature)\n",
        "    return np.array(features)\n",
        "\n",
        "# Reduzir dimensionalidade com PCA\n",
        "def apply_pca(features, n_components=50):\n",
        "    pca = PCA(n_components=n_components, random_state=42)\n",
        "    reduced_features = pca.fit_transform(features)\n",
        "    return reduced_features, pca\n",
        "\n",
        "# Pré-processamento\n",
        "print(\"Extraindo recursos com HOG...\")\n",
        "hog_features = extract_features(processed_images)\n",
        "\n",
        "print(\"Reduzindo dimensionalidade com PCA...\")\n",
        "X_reduced, pca = apply_pca(hog_features)\n",
        "\n",
        "# Divisão do dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_reduced,\n",
        "    labels_encoded,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels_encoded\n",
        ")\n",
        "\n",
        "print(f\"Formato do conjunto de treinamento: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Formato do conjunto de teste: {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "# Usar MiniBatchKMeans\n",
        "n_clusters = len(class_names)\n",
        "kmeans = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, batch_size=100, max_iter=500)\n",
        "kmeans.fit(X_train)\n",
        "\n",
        "# Ajustar rótulos de cluster para coincidir com as classes reais\n",
        "labels_map = {}\n",
        "for cluster_idx in range(n_clusters):\n",
        "    mask = (kmeans.labels_ == cluster_idx)\n",
        "    true_labels = y_train[mask]\n",
        "    if len(true_labels) > 0:\n",
        "        labels_map[cluster_idx] = mode(true_labels, keepdims=True).mode[0]\n",
        "\n",
        "# Predizer e mapear os clusters para as classes reais\n",
        "y_pred = kmeans.predict(X_test)\n",
        "y_pred_mapped = np.array([labels_map[cluster] for cluster in y_pred])\n",
        "\n",
        "# Decodificar os rótulos\n",
        "y_pred_mapped = label_encoder.inverse_transform(y_pred_mapped)\n",
        "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "# Avaliar o desempenho\n",
        "accuracy = accuracy_score(y_test_decoded, y_pred_mapped)\n",
        "print(f\"Acurácia do MiniBatchKMeans após otimização: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T18:12:11.98887Z",
          "iopub.execute_input": "2024-11-24T18:12:11.989895Z",
          "iopub.status.idle": "2024-11-24T18:15:38.477246Z",
          "shell.execute_reply.started": "2024-11-24T18:12:11.989842Z",
          "shell.execute_reply": "2024-11-24T18:15:38.47515Z"
        },
        "id": "7q-Bdr3fntAR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the name of the model as \"Inception\".\n",
        "name = \"Inception\"\n",
        "\n",
        "# Load the pre-trained InceptionV3 model, freeze its weights and exclude its final classification layer.\n",
        "base_model = InceptionV3(include_top=False, input_shape=(256,256,3), weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a sequential model with the InceptionV3 base model, a global average pooling layer, two fully connected layers, and a final softmax classification layer.\n",
        "inception = Sequential([\n",
        "    base_model,\n",
        "    GAP(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "], name=name)\n",
        "\n",
        "# Compile the model with sparse categorical cross-entropy as the loss function, Adam optimizer and accuracy as the evaluation metric.\n",
        "inception.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model using the training and validation datasets, using 50 epochs and the previously defined callbacks.\n",
        "history_inception = fit_model_cnn(inception, name)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-24T18:24:55.850583Z",
          "iopub.execute_input": "2024-11-24T18:24:55.852259Z",
          "iopub.status.idle": "2024-11-24T20:45:58.93588Z",
          "shell.execute_reply.started": "2024-11-24T18:24:55.8522Z",
          "shell.execute_reply": "2024-11-24T20:45:58.932203Z"
        },
        "id": "u8Sau9KHntAS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the name of the model as \"Xception\".\n",
        "name = \"Xception\"\n",
        "\n",
        "# Load the pre-trained Xception model, freeze its weights and exclude its final classification layer.\n",
        "base_model = Xception(include_top=False, input_shape=(256,256,3), weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a sequential model with the Xception base model, a global average pooling layer, two fully connected layers, and a final softmax classification layer.\n",
        "xception = Sequential([\n",
        "    base_model,\n",
        "    GAP(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "], name=name)\n",
        "\n",
        "# Compile the model with sparse categorical cross-entropy as the loss function, Adam optimizer and accuracy as the evaluation metric.\n",
        "xception.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model using the training and validation datasets, using 50 epochs and the previously defined callbacks.\n",
        "history_xception = fit_model_cnn(xception, name)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:33:32.775502Z",
          "iopub.execute_input": "2024-11-25T00:33:32.776008Z",
          "iopub.status.idle": "2024-11-25T00:38:07.456726Z",
          "shell.execute_reply.started": "2024-11-25T00:33:32.775971Z",
          "shell.execute_reply": "2024-11-25T00:38:07.45469Z"
        },
        "id": "lBqAAlnRntAS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, show_shapes = True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:28:32.808837Z",
          "iopub.execute_input": "2024-11-25T00:28:32.809534Z",
          "iopub.status.idle": "2024-11-25T00:28:33.419043Z",
          "shell.execute_reply.started": "2024-11-25T00:28:32.809439Z",
          "shell.execute_reply": "2024-11-25T00:28:33.41763Z"
        },
        "id": "qOc0RxfJntAS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(inception, show_shapes = True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:28:42.266488Z",
          "iopub.execute_input": "2024-11-25T00:28:42.266999Z",
          "iopub.status.idle": "2024-11-25T00:28:42.525702Z",
          "shell.execute_reply.started": "2024-11-25T00:28:42.266959Z",
          "shell.execute_reply": "2024-11-25T00:28:42.524408Z"
        },
        "id": "EiJueiRZntAS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(xception, show_shapes = True)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:28:49.596144Z",
          "iopub.execute_input": "2024-11-25T00:28:49.596555Z",
          "iopub.status.idle": "2024-11-25T00:28:49.871737Z",
          "shell.execute_reply.started": "2024-11-25T00:28:49.59652Z",
          "shell.execute_reply": "2024-11-25T00:28:49.87053Z"
        },
        "id": "2sno1rDAntAT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Dados de treinamento e validação\n",
        "train_loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "epoch = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot com sns.lineplot\n",
        "sns.lineplot(x=epoch, y=train_loss, label='Training Loss')\n",
        "sns.lineplot(x=epoch, y=val_loss, label='Validation Loss')\n",
        "\n",
        "# Personalizar o gráfico\n",
        "plt.title('Training and Validation Loss\\n')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:31:13.290189Z",
          "iopub.execute_input": "2024-11-25T00:31:13.290815Z",
          "iopub.status.idle": "2024-11-25T00:31:13.743281Z",
          "shell.execute_reply.started": "2024-11-25T00:31:13.290768Z",
          "shell.execute_reply": "2024-11-25T00:31:13.741969Z"
        },
        "id": "4QAk_XcFntAT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Dados de treinamento e validação\n",
        "train_loss = history_inception.history['loss']\n",
        "val_loss = history_inception.history['val_loss']\n",
        "epoch = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot com sns.lineplot\n",
        "sns.lineplot(x=epoch, y=train_loss, label='Training Loss')\n",
        "sns.lineplot(x=epoch, y=val_loss, label='Validation Loss')\n",
        "\n",
        "# Personalizar o gráfico\n",
        "plt.title('Training and Validation Loss\\n')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:32:35.297774Z",
          "iopub.execute_input": "2024-11-25T00:32:35.298289Z",
          "iopub.status.idle": "2024-11-25T00:32:35.712033Z",
          "shell.execute_reply.started": "2024-11-25T00:32:35.298247Z",
          "shell.execute_reply": "2024-11-25T00:32:35.710649Z"
        },
        "id": "bivrBdBHntAT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Dados de treinamento e validação\n",
        "train_loss = history_xception.history['loss']\n",
        "val_loss = history_xception.history['val_loss']\n",
        "epoch = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot com sns.lineplot\n",
        "sns.lineplot(x=epoch, y=train_loss, label='Training Loss')\n",
        "sns.lineplot(x=epoch, y=val_loss, label='Validation Loss')\n",
        "\n",
        "# Personalizar o gráfico\n",
        "plt.title('Training and Validation Loss\\n')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:33:16.629425Z",
          "iopub.execute_input": "2024-11-25T00:33:16.629935Z",
          "iopub.status.idle": "2024-11-25T00:33:16.692546Z",
          "shell.execute_reply.started": "2024-11-25T00:33:16.629894Z",
          "shell.execute_reply": "2024-11-25T00:33:16.690669Z"
        },
        "id": "QNirTJ1hntAU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Dados de treinamento e validação\n",
        "train_acc = model_history.history['accuracy']\n",
        "val_acc = model_history.history['val_accuracy']\n",
        "epoch = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot com sns.lineplot\n",
        "sns.lineplot(x=epoch, y=train_loss, label='Training accuracy')\n",
        "sns.lineplot(x=epoch, y=val_loss, label='Validation accuracy')\n",
        "\n",
        "# Personalizar o gráfico\n",
        "plt.title('Training and Validation Accuracy\\n')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:40:08.861695Z",
          "iopub.execute_input": "2024-11-25T00:40:08.862222Z",
          "iopub.status.idle": "2024-11-25T00:40:09.267236Z",
          "shell.execute_reply.started": "2024-11-25T00:40:08.86218Z",
          "shell.execute_reply": "2024-11-25T00:40:09.265653Z"
        },
        "id": "SrWa3HTQntAU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Dados de treinamento e validação\n",
        "train_acc = history_inception.history['accuracy']\n",
        "val_acc = history_inception.history['val_accuracy']\n",
        "epoch = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot com sns.lineplot\n",
        "sns.lineplot(x=epoch, y=train_loss, label='Training accuracy')\n",
        "sns.lineplot(x=epoch, y=val_loss, label='Validation accuracy')\n",
        "\n",
        "# Personalizar o gráfico\n",
        "plt.title('Training and Validation Accuracy\\n')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:41:34.277093Z",
          "iopub.execute_input": "2024-11-25T00:41:34.277497Z",
          "iopub.status.idle": "2024-11-25T00:41:34.678046Z",
          "shell.execute_reply.started": "2024-11-25T00:41:34.277462Z",
          "shell.execute_reply": "2024-11-25T00:41:34.676556Z"
        },
        "id": "68GNI9dUntAU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Dados de treinamento e validação\n",
        "train_acc = history_xception.history['accuracy']\n",
        "val_acc = history_xception.history['val_accuracy']\n",
        "epoch = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plot com sns.lineplot\n",
        "sns.lineplot(x=epoch, y=train_loss, label='Training accuracy')\n",
        "sns.lineplot(x=epoch, y=val_loss, label='Validation accuracy')\n",
        "\n",
        "# Personalizar o gráfico\n",
        "plt.title('Training and Validation Accuracy\\n')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:43:36.188321Z",
          "iopub.execute_input": "2024-11-25T00:43:36.188862Z",
          "iopub.status.idle": "2024-11-25T00:43:36.245876Z",
          "shell.execute_reply.started": "2024-11-25T00:43:36.188821Z",
          "shell.execute_reply": "2024-11-25T00:43:36.243985Z"
        },
        "id": "3nnrNMugntAU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando a matriz de confusão\n",
        "conf_matrix = metrics.confusion_matrix(y_test_decoded, y_pred_mapped, labels=label_encoder.classes_)\n",
        "\n",
        "# Exibindo a matriz de confusão como um heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(\n",
        "    conf_matrix,\n",
        "    annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "    xticklabels=label_encoder.classes_,\n",
        "    yticklabels=label_encoder.classes_\n",
        ")\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.xlabel(\"Classes Preditas\")\n",
        "plt.ylabel(\"Classes Verdadeiras\")\n",
        "plt.show()\n",
        "\n",
        "# Gerando o classification_report\n",
        "class_report = metrics.classification_report(y_test_decoded, y_pred_mapped, target_names=label_encoder.classes_)\n",
        "print(\"Relatório de Classificação:\\n\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:44:24.012169Z",
          "iopub.execute_input": "2024-11-25T00:44:24.012715Z",
          "iopub.status.idle": "2024-11-25T00:44:24.704122Z",
          "shell.execute_reply.started": "2024-11-25T00:44:24.012675Z",
          "shell.execute_reply": "2024-11-25T00:44:24.702635Z"
        },
        "id": "_wQI90FuntAV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Obter rótulos verdadeiros e predições no conjunto de validação\n",
        "valid_data_ann.reset()  # Reinicia o gerador para evitar problemas de indexação\n",
        "y_true = valid_data_ann.classes  # Rótulos verdadeiros no conjunto de validação\n",
        "y_pred_proba = model.predict(valid_data_ann)  # Probabilidades previstas pelo modelo\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)  # Convertendo probabilidades para classes previstas\n",
        "\n",
        "# Decodificar os rótulos para exibir os nomes das classes\n",
        "class_names = list(valid_data_ann.class_indices.keys())  # Nome das classes do gerador\n",
        "y_true_decoded = [class_names[idx] for idx in y_true]\n",
        "y_pred_decoded = [class_names[idx] for idx in y_pred]\n",
        "\n",
        "# Matriz de Confusão\n",
        "conf_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Exibir Matriz de Confusão como heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(\n",
        "    conf_matrix,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names\n",
        ")\n",
        "plt.title(\"Matriz de Confusão - Modelo ANN\")\n",
        "plt.xlabel(\"Classes Preditas\")\n",
        "plt.ylabel(\"Classes Verdadeiras\")\n",
        "plt.show()\n",
        "\n",
        "# Relatório de Classificação\n",
        "class_report = metrics.classification_report(y_true, y_pred, target_names=class_names)\n",
        "print(\"Relatório de Classificação - Modelo ANN:\\n\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:45:00.071243Z",
          "iopub.execute_input": "2024-11-25T00:45:00.071832Z",
          "iopub.status.idle": "2024-11-25T00:46:12.367174Z",
          "shell.execute_reply.started": "2024-11-25T00:45:00.07179Z",
          "shell.execute_reply": "2024-11-25T00:46:12.365529Z"
        },
        "id": "MvIZoAdWntAV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Obter rótulos verdadeiros e predições no conjunto de validação\n",
        "valid_data_cnn.reset()  # Reinicia o gerador para evitar problemas de indexação\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:47:54.548511Z",
          "iopub.execute_input": "2024-11-25T00:47:54.549095Z",
          "iopub.status.idle": "2024-11-25T00:47:54.555581Z",
          "shell.execute_reply.started": "2024-11-25T00:47:54.549055Z",
          "shell.execute_reply": "2024-11-25T00:47:54.55377Z"
        },
        "id": "IrrV_8o3ntAV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = valid_data_cnn.classes  # Rótulos verdadeiros no conjunto de validação\n",
        "y_pred_proba = inception.predict(valid_data_cnn)  # Probabilidades previstas pelo modelo\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)  # Convertendo probabilidades para classes previstas\n",
        "\n",
        "# Decodificar os rótulos para exibir os nomes das classes\n",
        "class_names = list(valid_data_cnn.class_indices.keys())  # Nome das classes do gerador\n",
        "y_true_decoded = [class_names[idx] for idx in y_true]\n",
        "y_pred_decoded = [class_names[idx] for idx in y_pred]\n",
        "\n",
        "# Matriz de Confusão\n",
        "conf_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Exibir Matriz de Confusão como heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(\n",
        "    conf_matrix,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names\n",
        ")\n",
        "plt.title(\"Matriz de Confusão - Modelo CNN InceptionV3\")\n",
        "plt.xlabel(\"Classes Preditas\")\n",
        "plt.ylabel(\"Classes Verdadeiras\")\n",
        "plt.show()\n",
        "\n",
        "# Relatório de Classificação\n",
        "class_report = metrics.classification_report(y_true, y_pred, target_names=class_names)\n",
        "print(\"Relatório de Classificação - Modelo CNN InceptionV3:\\n\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-25T00:47:59.585841Z",
          "iopub.execute_input": "2024-11-25T00:47:59.586697Z",
          "iopub.status.idle": "2024-11-25T00:53:26.698718Z",
          "shell.execute_reply.started": "2024-11-25T00:47:59.586658Z",
          "shell.execute_reply": "2024-11-25T00:53:26.697428Z"
        },
        "id": "eLFWi4w2ntAV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = valid_data_cnn.classes  # Rótulos verdadeiros no conjunto de validação\n",
        "y_pred_proba = xception.predict(valid_data_cnn)  # Probabilidades previstas pelo modelo\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)  # Convertendo probabilidades para classes previstas\n",
        "\n",
        "# Decodificar os rótulos para exibir os nomes das classes\n",
        "class_names = list(valid_data_cnn.class_indices.keys())  # Nome das classes do gerador\n",
        "y_true_decoded = [class_names[idx] for idx in y_true]\n",
        "y_pred_decoded = [class_names[idx] for idx in y_pred]\n",
        "\n",
        "# Matriz de Confusão\n",
        "conf_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Exibir Matriz de Confusão como heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(\n",
        "    conf_matrix,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names\n",
        ")\n",
        "plt.title(\"Matriz de Confusão - Modelo CNN Xception\")\n",
        "plt.xlabel(\"Classes Preditas\")\n",
        "plt.ylabel(\"Classes Verdadeiras\")\n",
        "plt.show()\n",
        "\n",
        "# Relatório de Classificação\n",
        "class_report = metrics.classification_report(y_true, y_pred, target_names=class_names)\n",
        "print(\"Relatório de Classificação - Modelo CNN Xception:\\n\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "JDSFxJ9nntAV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste t independente para verificar se existe diferença entre as acurácias médias dos modelos de CNN InceptionV3 e Xception, para alfa = 5%:\n",
        "# H0: AccMediaInception = AccMediaXception VS H1: AccMediaInception < AccMediaXception;\n",
        "\n",
        "# Coletar as acurácias de validação:\n",
        "acc_inception = history_inception.history['val_accuracy']\n",
        "acc_xception = history_xception.history['val_accuracy']\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "t_stat, p_value = ttest_ind(acc_xception, acc_inception)\n",
        "\n",
        "print(\"estatística do teste: \" + t_stat + \", p-valor:\", p_value)\n",
        "\n",
        "if p_value < 0,05:\n",
        "    print(\"O modelo Xception possui maior acurácia média.\")\n",
        "else:\n",
        "    print(\"Não é possível concluir que existem diferenças significativas nas acurácias médias dos modelos de CNN.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "uLzg8JUzntAW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Código para implementar a aplicação web com o melhor modelo escolhido dos 4 (provavelmente o InceptionV3):\n",
        "from tensorflow.keras.models import load_model\n",
        "import streamlit as st\n",
        "\n",
        "st.header('Image Classification Model')\n",
        "best_model = load_model('caminho/ate/o/arquivo/do/modelo/salvo/Xception.keras')\n",
        "data_cat = class_names_dict.values()\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "image = st.text_input('Enter Image name','Exemplo_Animal.jpg')\n",
        "\n",
        "image_load = tf.keras.utils.load_img(image, target_size=(img_height,img_width))\n",
        "img_arr = tf.keras.utils.array_to_img(image_load)\n",
        "img_bat=tf.expand_dims(img_arr,0)\n",
        "\n",
        "predict = best_model.predict(img_bat)\n",
        "\n",
        "score = tf.nn.softmax(predict)\n",
        "st.image(image, width=200)\n",
        "st.write('Veg/Fruit in image is ' + data_cat[np.argmax(score)])\n",
        "st.write('With accuracy of ' + str(np.max(score)*100))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "4YGZxOsAntAW"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}